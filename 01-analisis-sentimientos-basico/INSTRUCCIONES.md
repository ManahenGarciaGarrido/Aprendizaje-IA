# INSTRUCCIONES R√ÅPIDAS - Proyecto 1

## ¬øD√≥nde ejecutar?

**TU PORT√ÅTIL es PERFECTO** (no necesitas GPU)
- Los modelos son ligeros (ML tradicional, no deep learning)
- Tiempo estimado: 5-15 minutos
- Requiere: ~4GB RAM, ~500MB disco

**Alternativa:** Google Colab (solo si tu PC tiene <4GB RAM)

---

## Instalaci√≥n y Ejecuci√≥n

### Paso 1: Instalar dependencias

```bash
# Navegar a la carpeta del proyecto
cd 01-analisis-sentimientos-basico

# Instalar paquetes necesarios
pip install numpy pandas scikit-learn nltk tensorflow-datasets joblib matplotlib seaborn
```

### Paso 2: Entrenar el modelo

```bash
# Desde la carpeta src/
cd src
python train_model.py
```

**¬øQu√© hace este script?**
- Descarga dataset IMDB (25k reviews, ~80MB) - solo la 1¬™ vez
- Preprocesa textos (limpieza, tokenizaci√≥n, lemmatizaci√≥n)
- Entrena 2 modelos (Naive Bayes y Logistic Regression)
- Guarda el mejor modelo en `models/`

**Tiempo:** 2-5 minutos en port√°til normal

### Paso 3: Probar predicciones

```bash
python predict.py
```

**¬øQu√© hace?**
- Carga el modelo entrenado
- Muestra ejemplos de predicci√≥n
- Permite modo interactivo para tus propios textos

---

## Opciones de uso

### Opci√≥n A: Scripts Python (Recomendado para aprender)

```bash
# 1. Probar preprocesamiento
cd src/
python preprocessing.py

# 2. Entrenar modelo completo
python train_model.py

# 3. Hacer predicciones
python predict.py
```

### Opci√≥n B: Notebook Jupyter

```bash
# Instalar Jupyter si no lo tienes
pip install jupyter

# Abrir notebook
jupyter notebook notebook.ipynb
```

---

## Configuraci√≥n personalizada

### Cambiar cantidad de datos

Edita `train_model.py` l√≠nea 315:
```python
MAX_SAMPLES = 10000  # Cambiar a 25000 para usar todo el dataset
```

### Usar CSV propio

Si tienes tu propio dataset CSV:
```python
# En train_model.py, reemplaza load_data_from_tfds() por:
texts, labels = load_data_from_csv('ruta/a/tu/archivo.csv')
```

### üåç IMPORTANTE: Idioma del modelo

**El modelo est√° entrenado en INGL√âS** (dataset IMDB de reviews en ingl√©s).

**Para usar textos en ingl√©s** (recomendado):
- ‚úÖ Ya est√° configurado por defecto
- Los textos deben estar en ingl√©s para obtener buenos resultados
- Ejemplos: "This movie is amazing!", "Terrible film, waste of time"

**Para entrenar con textos en espa√±ol:**

1. Necesitas un dataset en espa√±ol (el IMDB es solo ingl√©s)
2. Cambia el idioma del preprocesador en `train_model.py` l√≠nea 320:
   ```python
   processed_texts = batch_preprocess(texts, language='spanish')
   ```
3. Cambia el idioma en `predict.py` l√≠nea 64:
   ```python
   self.preprocessor = TextPreprocessor(language='spanish')
   ```
4. Opciones de datasets en espa√±ol:
   - Kaggle: "Spanish Sentiment Analysis"
   - Twitter datasets
   - Reviews de productos en espa√±ol

**¬øPor qu√© el idioma es importante?**
- Las stopwords cambian: "the, a, is" (ingl√©s) vs "el, la, es" (espa√±ol)
- El lemmatizer funciona diferente seg√∫n el idioma
- Si el idioma no coincide, las predicciones ser√°n incorrectas

---

## Soluci√≥n de problemas

### Error: "No module named 'nltk'"
```bash
pip install nltk
```

### Error: NLTK resources not found
```python
# Ejecutar en Python:
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
```

### Error: "tensorflow_datasets not found"
```bash
pip install tensorflow-datasets
```

### Dataset IMDB no descarga
- Verifica conexi√≥n a internet
- Alternativa: descarga manual desde Kaggle

---

## Resultados esperados

**Accuracy esperado:** 85-90%
- Naive Bayes: ~84-87%
- Logistic Regression: ~87-90%

**Si obtienes menor accuracy:**
- Aumenta `MAX_SAMPLES` a 25000
- Aumenta `max_features` en TfidfVectorizer

---

## Pr√≥ximos pasos

1. Ejecuta los scripts y entiende cada paso
2. Experimenta con el c√≥digo:
   - Cambia hiperpar√°metros
   - Prueba otros modelos (SVM)
   - Analiza palabras m√°s importantes
3. Lee los comentarios en el c√≥digo
4. Pasa al Proyecto 2

---

## Conceptos clave aprendidos

- Preprocesamiento de texto (tokenizaci√≥n, lemmatizaci√≥n, stopwords)
- Vectorizaci√≥n (TF-IDF vs Bag of Words)
- Modelos de clasificaci√≥n (Naive Bayes, Logistic Regression)
- Evaluaci√≥n (Accuracy, Precision, Recall, F1-Score)
- Pipeline completo de ML

---

¬øDudas? Revisa los comentarios en el c√≥digo - cada l√≠nea est√° explicada!
