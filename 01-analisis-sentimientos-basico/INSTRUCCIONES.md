# âš¡ INSTRUCCIONES RÃPIDAS - Proyecto 1

## ğŸ¯ Â¿DÃ³nde ejecutar?

**âœ… TU PORTÃTIL es PERFECTO** (no necesitas GPU)
- Los modelos son ligeros (ML tradicional, no deep learning)
- Tiempo estimado: 5-15 minutos
- Requiere: ~4GB RAM, ~500MB disco

**Alternativa:** Google Colab (solo si tu PC tiene <4GB RAM)

---

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### Paso 1: Instalar dependencias

```bash
# Navegar a la carpeta del proyecto
cd 01-analisis-sentimientos-basico

# Instalar paquetes necesarios
pip install numpy pandas scikit-learn nltk tensorflow-datasets joblib matplotlib seaborn
```

### Paso 2: Entrenar el modelo

```bash
# Desde la carpeta src/
cd src
python train_model.py
```

**Â¿QuÃ© hace este script?**
- Descarga dataset IMDB (25k reviews, ~80MB) - solo la 1Âª vez
- Preprocesa textos (limpieza, tokenizaciÃ³n, lemmatizaciÃ³n)
- Entrena 2 modelos (Naive Bayes y Logistic Regression)
- Guarda el mejor modelo en `models/`

**Tiempo:** 2-5 minutos en portÃ¡til normal

### Paso 3: Probar predicciones

```bash
python predict.py
```

**Â¿QuÃ© hace?**
- Carga el modelo entrenado
- Muestra ejemplos de predicciÃ³n
- Permite modo interactivo para tus propios textos

---

## ğŸ“Š Opciones de uso

### OpciÃ³n A: Scripts Python (Recomendado para aprender)

```bash
# 1. Probar preprocesamiento
cd src/
python preprocessing.py

# 2. Entrenar modelo completo
python train_model.py

# 3. Hacer predicciones
python predict.py
```

### OpciÃ³n B: Notebook Jupyter

```bash
# Instalar Jupyter si no lo tienes
pip install jupyter

# Abrir notebook
jupyter notebook notebook.ipynb
```

---

## ğŸ”§ ConfiguraciÃ³n personalizada

### Cambiar cantidad de datos

Edita `train_model.py` lÃ­nea 315:
```python
MAX_SAMPLES = 10000  # Cambiar a 25000 para usar todo el dataset
```

### Usar CSV propio

Si tienes tu propio dataset CSV:
```python
# En train_model.py, reemplaza load_data_from_tfds() por:
texts, labels = load_data_from_csv('ruta/a/tu/archivo.csv')
```

---

## â“ SoluciÃ³n de problemas

### Error: "No module named 'nltk'"
```bash
pip install nltk
```

### Error: NLTK resources not found
```python
# Ejecutar en Python:
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
```

### Error: "tensorflow_datasets not found"
```bash
pip install tensorflow-datasets
```

### Dataset IMDB no descarga
- Verifica conexiÃ³n a internet
- Alternativa: descarga manual desde Kaggle

---

## ğŸ“ˆ Resultados esperados

**Accuracy esperado:** 85-90%
- Naive Bayes: ~84-87%
- Logistic Regression: ~87-90%

**Si obtienes menor accuracy:**
- Aumenta `MAX_SAMPLES` a 25000
- Aumenta `max_features` en TfidfVectorizer

---

## ğŸ’¡ PrÃ³ximos pasos

1. âœ… Ejecuta los scripts y entiende cada paso
2. ğŸ”¬ Experimenta con el cÃ³digo:
   - Cambia hiperparÃ¡metros
   - Prueba otros modelos (SVM)
   - Analiza palabras mÃ¡s importantes
3. ğŸ“ Lee los comentarios en el cÃ³digo
4. ğŸ¯ Pasa al Proyecto 2

---

## ğŸ“š Conceptos clave aprendidos

- âœ… Preprocesamiento de texto (tokenizaciÃ³n, lemmatizaciÃ³n, stopwords)
- âœ… VectorizaciÃ³n (TF-IDF vs Bag of Words)
- âœ… Modelos de clasificaciÃ³n (Naive Bayes, Logistic Regression)
- âœ… EvaluaciÃ³n (Accuracy, Precision, Recall, F1-Score)
- âœ… Pipeline completo de ML

---

Â¿Dudas? Revisa los comentarios en el cÃ³digo - cada lÃ­nea estÃ¡ explicada!
