{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1: Análisis de Sentimientos en Texto\n",
    "## Clasificación de Reseñas de Películas IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Descargar recursos NLTK (ejecutar una vez)\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cargar el dataset IMDB\n",
    "# Opción 1: Usar tensorflow_datasets\n",
    "# import tensorflow_datasets as tfds\n",
    "# dataset = tfds.load('imdb_reviews', split='train', as_supervised=True)\n",
    "\n",
    "# Opción 2: Descargar manualmente y cargar con pandas\n",
    "# df = pd.read_csv('data/IMDB-Dataset.csv')\n",
    "\n",
    "# TODO: Explorar el dataset\n",
    "# - Ver las primeras filas\n",
    "# - Verificar forma del dataset\n",
    "# - Revisar distribución de clases\n",
    "# - Visualizar ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar funciones de preprocesamiento\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Limpia el texto:\n",
    "    - Convierte a minúsculas\n",
    "    - Elimina caracteres especiales\n",
    "    - Elimina números\n",
    "    - Elimina espacios extra\n",
    "    \"\"\"\n",
    "    # TODO: Implementar limpieza\n",
    "    pass\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesa el texto completo:\n",
    "    - Limpia\n",
    "    - Tokeniza\n",
    "    - Elimina stopwords\n",
    "    - Lematiza\n",
    "    \"\"\"\n",
    "    # TODO: Implementar preprocesamiento completo\n",
    "    pass\n",
    "\n",
    "# TODO: Aplicar preprocesamiento a todo el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorización del Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar Bag of Words\n",
    "# vectorizer = CountVectorizer(max_features=5000)\n",
    "\n",
    "# TODO: Implementar TF-IDF\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# TODO: Transformar el texto a vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. División de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividir en train/test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrenar Naive Bayes\n",
    "# nb_model = MultinomialNB()\n",
    "# nb_model.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Entrenar Logistic Regression\n",
    "# lr_model = LogisticRegression()\n",
    "# lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hacer predicciones\n",
    "# y_pred_nb = nb_model.predict(X_test)\n",
    "# y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# TODO: Calcular métricas\n",
    "# print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# TODO: Crear matriz de confusión\n",
    "# cm = confusion_matrix(y_test, y_pred_nb)\n",
    "# sns.heatmap(cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análisis de Features Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualizar palabras más importantes\n",
    "# Obtener coeficientes del modelo\n",
    "# Mostrar top palabras positivas y negativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Predicción en Textos Nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predice el sentimiento de un texto nuevo\n",
    "    \"\"\"\n",
    "    # TODO: Implementar predicción\n",
    "    pass\n",
    "\n",
    "# TODO: Probar con ejemplos\n",
    "# test_reviews = [\n",
    "#     \"This movie was absolutely amazing! Best film I've ever seen.\",\n",
    "#     \"Terrible movie, waste of time and money.\"\n",
    "# ]\n",
    "\n",
    "# for review in test_reviews:\n",
    "#     sentiment = predict_sentiment(review, best_model, vectorizer)\n",
    "#     print(f\"Review: {review}\")\n",
    "#     print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Guardar el mejor modelo\n",
    "# import joblib\n",
    "# joblib.dump(best_model, '../models/sentiment_model.pkl')\n",
    "# joblib.dump(vectorizer, '../models/vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "TODO: Documentar:\n",
    "- ¿Qué modelo funcionó mejor y por qué?\n",
    "- ¿Qué accuracy lograste?\n",
    "- ¿Cuáles fueron las palabras más importantes?\n",
    "- ¿Qué aprendiste sobre análisis de sentimientos?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
